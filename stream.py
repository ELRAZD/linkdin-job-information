import streamlit as st
import pandas as pd
import os
from main import Data_Mining

CSV_PATH = r"C:\Users\Elyar\Desktop\linkdin-job-information\job_data.csv"

st.set_page_config(page_title="LinkedIn Job Scraper", layout="centered")
st.title("ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ø²Ù†Ø¯Ù‡ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ LinkedIn")

with st.form("job_form"):
    job_title = st.text_input("ğŸ”¤ Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„", value="java")
    location = st.text_input("ğŸ“ Ù…Ú©Ø§Ù†", value="germany")
    count = st.number_input("ğŸ“¦ ØªØ¹Ø¯Ø§Ø¯ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬", min_value=1, value=50)
    submitted = st.form_submit_button("ğŸš€ Ø´Ø±ÙˆØ¹ Ø¬Ø³ØªØ¬Ùˆ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬")

if submitted:
    scraper = Data_Mining()
    try:
        with st.spinner("ğŸ§­ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±..."):
            scraper.setup_driver()


        with st.expander("ğŸ” Ù…Ø±Ø­Ù„Ù‡ ÙˆØ±ÙˆØ¯ Ø¨Ù‡ LinkedIn", expanded=True):
            st.markdown("âœ… Ù„Ø·ÙØ§Ù‹ Ø¯Ø± Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ø§Ø²Ø´Ø¯Ù‡ ÙˆØ§Ø±Ø¯ Ø­Ø³Ø§Ø¨ LinkedIn Ø®ÙˆØ¯ Ø´ÙˆÛŒØ¯ Ùˆ Ú©Ù¾Ú†Ø§ Ø±Ø§ Ø­Ù„ Ú©Ù†ÛŒØ¯.")
            st.code("â³ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯ ØªØ§ Ø¨Ø¹Ø¯ Ø§Ø² ÙˆØ±ÙˆØ¯ Ø¨Ù‡ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ LinkedIn Ø¨Ø±ÙˆÛŒØ¯...")


        scraper.login()

        with st.spinner("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø´ØºÙ„..."):
            scraper.jobs(job_title, location)

        with st.spinner("ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª..."):
            scraper.job_scraper(count)

        st.success("âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")

    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬: {e}")

    finally:
        try:
            scraper.driver.quit()
        except:
            pass


if os.path.exists(CSV_PATH):
    st.subheader("ğŸ“‹ Ù†ØªØ§ÛŒØ¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:")
    df = pd.read_csv(CSV_PATH)
    st.dataframe(df, use_container_width=True)